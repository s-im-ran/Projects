{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPCUjngkll4EcKyRxZn+CC6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-im-ran/Projects/blob/main/Sentiment_Analysis_Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment analysis using Logistic  Regression"
      ],
      "metadata": {
        "id": "FFGM0U72HKx9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynBA3CqaHJ0p"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPfAEWcQHKia",
        "outputId": "f40a1ac4-d54e-4e2f-e878-e69db501c341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process(tweet):\n",
        "    tokens = word_tokenize(tweet)\n",
        "    tokens = [token.lower() for token in tokens]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    fil_tokens = [token for token in tokens if token not in stop_words]\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in fil_tokens]\n",
        "    preprocessed_tweet = ' '.join(stemmed_tokens)\n",
        "    return preprocessed_tweet"
      ],
      "metadata": {
        "id": "bq5cKUnwHKl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_freqs(tweets, sy):\n",
        "    freqs = {}\n",
        "\n",
        "    for y, tweet in zip(sy, tweets):\n",
        "        preprocessed_tweet = process(tweet)\n",
        "        words = preprocessed_tweet.split()\n",
        "\n",
        "        for word in words:\n",
        "            pair = (word, y)\n",
        "            if pair in freqs:\n",
        "                freqs[pair] += 1\n",
        "            else:\n",
        "                freqs[pair] = 1\n",
        "\n",
        "    return freqs\n"
      ],
      "metadata": {
        "id": "EGCXr01KKcN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"twitter_samples\")\n",
        "from nltk.corpus import twitter_samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNI0-j_7MBQV",
        "outputId": "6fb560bf-b22c-44ec-c0af-8485bfa45989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pos=twitter_samples.strings('positive_tweets.json')\n",
        "neg=twitter_samples.strings('negative_tweets.json')"
      ],
      "metadata": {
        "id": "VIiQGCSUP_xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pos=pos[4000:]\n",
        "train_pos=pos[:4000]\n",
        "test_neg=neg[4000:]\n",
        "train_neg=neg[:4000]\n"
      ],
      "metadata": {
        "id": "F3Dce43XME8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x=train_pos+train_neg\n",
        "test_x=test_pos+test_neg"
      ],
      "metadata": {
        "id": "FWJLbiMqMo_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = [1] * len(train_pos) + [0] * len(train_neg)\n",
        "test_y = [1] * len(test_pos) + [0] * len(test_neg)"
      ],
      "metadata": {
        "id": "XlOdBLLzRIuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = build_freqs(train_x, train_y)\n",
        "print(\"type(freqs) = \" + str(type(freqs)))\n",
        "print(\"len(freqs) = \" + str(len(freqs.keys())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzJ_OjVuUjpr",
        "outputId": "76dfddbb-f695-4fc1-efe8-2775e23f7649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(freqs) = <class 'dict'>\n",
            "len(freqs) = 18658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(freqs.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcvY8CYIs56-",
        "outputId": "1e621600-c017-4fee-f309-0456a5338755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('A positive tweet: \\n', train_x[22])\n",
        "print('Processed version of the tweet: \\n', process(train_x[22]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU0G1PCWUopi",
        "outputId": "e41b4542-7f76-461c-9471-f02c30202ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A positive tweet: \n",
            " @gculloty87 Yeah I suppose she was lol! Chat in a bit just off out x :))\n",
            "Processed version of the tweet: \n",
            " @ gculloty87 yeah suppos lol ! chat bit x : ) )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "h333bYaBVB6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "train_x_vectorized = vectorizer.fit_transform(train_x)\n",
        "test_x_vectorized = vectorizer.transform(test_x)"
      ],
      "metadata": {
        "id": "NfE4OLv_WASg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(train_x_vectorized, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "XKdZmc6VWJgO",
        "outputId": "a2051e76-14e1-44aa-91fe-f58b565bbe76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_y = model.predict(test_x_vectorized)"
      ],
      "metadata": {
        "id": "bOoF08NlWOZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(test_y, pred_y)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "class_report = classification_report(test_y, pred_y)\n",
        "print(\"Classification Report:\\n\", class_report)\n",
        "\n",
        "conf_matrix = confusion_matrix(test_y, pred_y)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7hs5ClRWTPf",
        "outputId": "80d64d7b-fc2d-4ff4-f8f1-4950bd1ce5a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.76\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.79      0.77      1000\n",
            "           1       0.78      0.73      0.75      1000\n",
            "\n",
            "    accuracy                           0.76      2000\n",
            "   macro avg       0.76      0.76      0.76      2000\n",
            "weighted avg       0.76      0.76      0.76      2000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[792 208]\n",
            " [272 728]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the sentiment of a random tweet from the testing set\n",
        "import random\n",
        "random_tweet_index = random.randint(0, len(test_x) - 1)\n",
        "random_tweet = test_x[random_tweet_index]\n",
        "print(random_tweet)\n",
        "preprocessed_random_tweet = process(random_tweet)\n",
        "random_tweet_vectorized = vectorizer.transform([preprocessed_random_tweet])\n",
        "sentiment_prediction = model.predict(random_tweet_vectorized)\n",
        "if(sentiment_prediction==1):\n",
        "  print('positive sentiment')\n",
        "else:\n",
        "  print('negative sentiment')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BED7Ghi9XS4Y",
        "outputId": "54fe093d-5770-4853-8363-111efcd4fa27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excited for the weekend :-)\n",
            "negative sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the sentiment of a random tweet as input\n",
        "inp1='I love to be close by my parents.'\n",
        "inp='i love school'\n",
        "preprocessed_input =process(inp)\n",
        "input_vectorized = vectorizer.transform([preprocessed_input])\n",
        "sentiment_prediction = model.predict(input_vectorized)\n",
        "if sentiment_prediction==1:\n",
        "  print('Positive sentiment')\n",
        "elif sentiment_prediction == 0:\n",
        "    print('Negative sentiment')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4eSTgHTWV0u",
        "outputId": "cc2261c6-399c-4b05-b9c4-70ce386dd04f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive sentiment\n"
          ]
        }
      ]
    }
  ]
}